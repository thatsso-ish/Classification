{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages\n",
    "\n",
    "Importing the necessary packages for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Displays output inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for Handing Errors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "Loading the dataset from the 'train.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, we perform various data cleaning tasks to prepare the dataset for further analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBI revises definition of politically-exposed ...</td>\n",
       "      <td>The central bank has also asked chairpersons a...</td>\n",
       "      <td>The Reserve Bank of India (RBI) has changed th...</td>\n",
       "      <td>https://indianexpress.com/article/business/ban...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDTV Q2 net profit falls 57.4% to Rs 5.55 cror...</td>\n",
       "      <td>NDTV's consolidated revenue from operations wa...</td>\n",
       "      <td>Broadcaster New Delhi Television Ltd on Monday...</td>\n",
       "      <td>https://indianexpress.com/article/business/com...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akasa Air ‘well capitalised’, can grow much fa...</td>\n",
       "      <td>The initial share sale will be open for public...</td>\n",
       "      <td>Homegrown server maker Netweb Technologies Ind...</td>\n",
       "      <td>https://indianexpress.com/article/business/mar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India’s current account deficit declines sharp...</td>\n",
       "      <td>The current account deficit (CAD) was 3.8 per ...</td>\n",
       "      <td>India’s current account deficit declined sharp...</td>\n",
       "      <td>https://indianexpress.com/article/business/eco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>States borrowing cost soars to 7.68%, highest ...</td>\n",
       "      <td>The prices shot up reflecting the overall high...</td>\n",
       "      <td>States have been forced to pay through their n...</td>\n",
       "      <td>https://indianexpress.com/article/business/eco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India’s Russian oil imports slip in Oct, Saudi...</td>\n",
       "      <td>Russian crude accounted for nearly 35 per cent...</td>\n",
       "      <td>India’s oil imports from Russia averaged 1.57 ...</td>\n",
       "      <td>https://indianexpress.com/article/business/com...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neelkanth Mishra appointed part-time chairpers...</td>\n",
       "      <td>The board of the UIDAI comprises a chairperson...</td>\n",
       "      <td>Neelkanth Mishra, chief economist at Axis Bank...</td>\n",
       "      <td>https://indianexpress.com/article/business/eco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Centre issues advisory to social media platfor...</td>\n",
       "      <td>The IT ministry had earlier also issued adviso...</td>\n",
       "      <td>The Ministry of Electronics and IT (MeitY) has...</td>\n",
       "      <td>https://indianexpress.com/article/business/cen...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asian shares rise after eased pressure on bond...</td>\n",
       "      <td>US futures were little changed and oil prices ...</td>\n",
       "      <td>Shares advanced Wednesday in Asia, tracking Wa...</td>\n",
       "      <td>https://indianexpress.com/article/business/wor...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>India’s demand for electricity for ACs to exce...</td>\n",
       "      <td>India's demand for electricity for running hou...</td>\n",
       "      <td>nrIndia’s demand for electricity for running h...</td>\n",
       "      <td>https://indianexpress.com/article/business/eco...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  RBI revises definition of politically-exposed ...   \n",
       "1  NDTV Q2 net profit falls 57.4% to Rs 5.55 cror...   \n",
       "2  Akasa Air ‘well capitalised’, can grow much fa...   \n",
       "3  India’s current account deficit declines sharp...   \n",
       "4  States borrowing cost soars to 7.68%, highest ...   \n",
       "5  India’s Russian oil imports slip in Oct, Saudi...   \n",
       "6  Neelkanth Mishra appointed part-time chairpers...   \n",
       "7  Centre issues advisory to social media platfor...   \n",
       "8  Asian shares rise after eased pressure on bond...   \n",
       "9  India’s demand for electricity for ACs to exce...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The central bank has also asked chairpersons a...   \n",
       "1  NDTV's consolidated revenue from operations wa...   \n",
       "2  The initial share sale will be open for public...   \n",
       "3  The current account deficit (CAD) was 3.8 per ...   \n",
       "4  The prices shot up reflecting the overall high...   \n",
       "5  Russian crude accounted for nearly 35 per cent...   \n",
       "6  The board of the UIDAI comprises a chairperson...   \n",
       "7  The IT ministry had earlier also issued adviso...   \n",
       "8  US futures were little changed and oil prices ...   \n",
       "9  India's demand for electricity for running hou...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The Reserve Bank of India (RBI) has changed th...   \n",
       "1  Broadcaster New Delhi Television Ltd on Monday...   \n",
       "2  Homegrown server maker Netweb Technologies Ind...   \n",
       "3  India’s current account deficit declined sharp...   \n",
       "4  States have been forced to pay through their n...   \n",
       "5  India’s oil imports from Russia averaged 1.57 ...   \n",
       "6  Neelkanth Mishra, chief economist at Axis Bank...   \n",
       "7  The Ministry of Electronics and IT (MeitY) has...   \n",
       "8  Shares advanced Wednesday in Asia, tracking Wa...   \n",
       "9  nrIndia’s demand for electricity for running h...   \n",
       "\n",
       "                                                 url  category  \n",
       "0  https://indianexpress.com/article/business/ban...  business  \n",
       "1  https://indianexpress.com/article/business/com...  business  \n",
       "2  https://indianexpress.com/article/business/mar...  business  \n",
       "3  https://indianexpress.com/article/business/eco...  business  \n",
       "4  https://indianexpress.com/article/business/eco...  business  \n",
       "5  https://indianexpress.com/article/business/com...  business  \n",
       "6  https://indianexpress.com/article/business/eco...  business  \n",
       "7  https://indianexpress.com/article/business/cen...  business  \n",
       "8  https://indianexpress.com/article/business/wor...  business  \n",
       "9  https://indianexpress.com/article/business/eco...  business  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Summary\n",
    "\n",
    "The dataset contains news articles from various domains, including Business, Technology, Sports, Education, and Entertainment. Each row in the dataset represents a single news article and consists of the following columns:\n",
    "\n",
    "- **headlines**: The headline or title of the news article.\n",
    "- **description**: A brief description or summary of the news article's content.\n",
    "- **content**: The main body or text of the news article.\n",
    "- **url**: The URL or web address of the news article.\n",
    "- **category**: The category or domain to which the news article belongs (e.g., Business, Technology, Sports, etc.).\n",
    "\n",
    "This dataset will be used for training a machine learning model to classify news articles into their respective categories based on the provided features (headlines, description, content, and URL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Size\n",
    "\n",
    "The dataset contains a total of 5,520 rows (news articles) and 5 columns (features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5520, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the dataset has 5,520 instances (news articles) and 5 features (headlines, description, content, url, category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5520 entries, 0 to 5519\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   headlines    5520 non-null   object\n",
      " 1   description  5520 non-null   object\n",
      " 2   content      5520 non-null   object\n",
      " 3   url          5520 non-null   object\n",
      " 4   category     5520 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 215.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Information\n",
    "\n",
    "The DataFrame contains the following information:\n",
    "\n",
    "- It is a pandas DataFrame object.\n",
    "- The DataFrame has 5,520 rows (from index 0 to 5,519).\n",
    "- There are 5 columns in the DataFrame.\n",
    "- All columns are non-null, meaning there are no missing values.\n",
    "- All columns have the data type 'object', which typically represents string data.\n",
    "- The total memory usage of the DataFrame is approximately 215.8 KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def check_duplicates(self):\n",
    "        \"\"\"\n",
    "        Check for duplicate rows in the DataFrame and print the result.\n",
    "        \"\"\"\n",
    "        duplicate_rows = self.df[self.df.duplicated()]\n",
    "\n",
    "        if duplicate_rows.empty:\n",
    "            print(\"No duplicates found.\")\n",
    "        else:\n",
    "            print(\"Duplicates found!\")\n",
    "            print(duplicate_rows)\n",
    "\n",
    "    def check_missing_values(self):\n",
    "        \"\"\"\n",
    "        Check for missing values in the DataFrame and print the count of missing values in each column.\n",
    "        \"\"\"\n",
    "        missing_values_count = self.df.isnull().sum()\n",
    "        print(\"Missing values count per column:\")\n",
    "        print(missing_values_count)\n",
    "\n",
    "    def convert_columns_to_lowercase(self, columns):\n",
    "        \"\"\"\n",
    "        Convert specified columns to lowercase.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            self.df[column] = self.df[column].str.lower()\n",
    "\n",
    "    def remove_punctuation(self, columns):\n",
    "        \"\"\"\n",
    "        Remove punctuation from specified columns.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            self.df[column] = self.df[column].str.replace(f\"[{string.punctuation}]\", \" \", regex=True)\n",
    "\n",
    "    def clean_whitespace(self, columns):\n",
    "        \"\"\"\n",
    "        Trim whitespace and replace multiple spaces with a single space in specified columns.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            self.df[column] = self.df[column].str.strip()\n",
    "            self.df[column] = self.df[column].str.replace(\"\\s+\", \" \", regex=True)\n",
    "\n",
    "    def remove_stopwords(self, columns):\n",
    "        \"\"\"\n",
    "        Remove stopwords from specified columns.\n",
    "        \"\"\"\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        for column in columns:\n",
    "            self.df[column] = self.df[column].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "    def tokenize_columns(self, columns):\n",
    "        \"\"\"\n",
    "        Tokenize text in specified columns.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            self.df[column] = self.df[column].apply(word_tokenize)\n",
    "\n",
    "    def stem_columns(self, columns):\n",
    "        \"\"\"\n",
    "        Stem words in specified columns using PorterStemmer.\n",
    "        \"\"\"\n",
    "        stemmer = PorterStemmer()\n",
    "        \n",
    "        for column in columns:\n",
    "            self.df[column] = self.df[column].apply(lambda x: [stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataFrameProcessor(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Rows Check\n",
    "\n",
    "The following code checks for the presence of duplicate rows in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found.\n"
     ]
    }
   ],
   "source": [
    "processor.check_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Duplicates Found**\n",
    "\n",
    "The analysis has concluded that there are no duplicate entries in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Values and Print Count\n",
    "\n",
    "Before proceeding with any data manipulation or analysis, it's crucial to assess the quality of the dataset. One common issue in datasets is missing values, which can lead to biased or inaccurate analyses if not addressed properly. Below, we demonstrate how to check for missing values and print the count of missing values in each column of our DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count per column:\n",
      "headlines      0\n",
      "description    0\n",
      "content        0\n",
      "url            0\n",
      "category       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "processor.check_missing_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Missing Values Count Per Column\n",
    "\n",
    "After analyzing the dataset, we find that there are no missing values in any of the columns. Specifically, the counts are as follows:\n",
    "\n",
    "- **Headlines**: 0\n",
    "- **Description**: 0\n",
    "- **Content**: 0\n",
    "- **URL**: 0\n",
    "- **Category**: 0\n",
    "\n",
    "These results indicate that the dataset is clean and ready for further analysis without needing any preprocessing for missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Your Environment for NLP Tasks\n",
    "\n",
    "Before diving into NLP tasks with NLTK, it's crucial to set up your environment correctly. This involves installing the required libraries and downloading the necessary NLTK corpora and tokenizers. Follow these steps to ensure your setup is ready:\n",
    "\n",
    "1. **Import Necessary Libraries**\n",
    "\n",
    "First, you'll need to import the libraries that will be used for various NLP tasks. This includes standard Python libraries for string manipulation, as well as specific NLTK modules for tokenization, stop words removal, and stemming/lemmatization. Execute the following code to import these libraries:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the NLTK data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. **Download NLTK Data**\n",
    "\n",
    "Some NLTK functionalities depend on external data that needs to be downloaded manually. To ensure these functionalities work correctly, run the following commands in your Python environment to download the necessary NLTK data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ismae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ismae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ismae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercasing Text Columns in DataFrame\n",
    "\n",
    "To standardize the case of text data across different columns in a DataFrame, it's often beneficial to convert all text to lowercase. This ensures consistency in text comparisons and analyses. Below is the code to lowercase the text in specific columns of a DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.convert_columns_to_lowercase(['headlines', 'description', 'content', 'url', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet iterates over the specified columns ('headlines', 'description', 'content', 'url', and 'category') in the DataFrame `df` and applies the `.str.lower()` method to each, converting all text to lowercase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuation from Text Columns in DataFrame\n",
    "\n",
    "To enhance the cleanliness and uniformity of text data, it's common to remove punctuation marks. This can simplify text analysis and improve the performance of certain algorithms. Below is the code to remove punctuation from specific columns of a DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.remove_punctuation(['headlines', 'description', 'content', 'url', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet iterates over the specified columns ('headlines', 'description', 'content', 'url', and 'category') in the DataFrame `df` and applies the `.str.replace()` method with a regular expression to replace all punctuation marks with spaces. This helps in cleaning the text data by eliminating punctuation while preserving the textual content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text Columns in DataFrame by Stripping Whitespace and Replacing Multiple Spaces\n",
    "\n",
    "To further refine the text data in a DataFrame, it's important to remove leading and trailing whitespace and consolidate multiple consecutive spaces into single spaces. This enhances the readability and consistency of the text data. Below is the code to achieve this for specific columns of a DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.clean_whitespace(['headlines', 'description', 'content', 'url', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet iterates over the specified columns ('headlines', 'description', 'content', 'url', and 'category') in the DataFrame `df`. First, it uses `.str.strip()` to remove leading and trailing whitespace from each text entry. Then, it employs `.str.replace(\"\\s+\", \" \", regex=True)` to replace sequences of one or more whitespace characters (including spaces, tabs, and newlines) with a single space. This process cleanses the text data by normalizing whitespace usage, making the text cleaner and more uniform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop Words from Text Columns in DataFrame\n",
    "\n",
    "Stop words are commonly used words that do not carry much meaning in the context of text analysis and can be safely removed to reduce noise in the data. Below is the code to remove English stop words from specific columns of a DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.remove_stopwords(['headlines', 'description', 'content', 'url', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet iterates over the specified columns ('headlines', 'description', 'content', 'url', and 'category') in the DataFrame `df`. For each column, it applies a lambda function that splits the text into individual words, filters out stop words, and then joins the remaining words back together with spaces. This process removes stop words from the text data, thereby enhancing the focus on more meaningful words and phrases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Text Columns in DataFrame Using NLTK\n",
    "\n",
    "Tokenization is the process of breaking down text into individual words or tokens, which is a fundamental step in many natural language processing (NLP) tasks. Below is the code to tokenize the text in specific columns of a DataFrame using NLTK's `word_tokenize` function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenize_columns(['headlines', 'description', 'content', 'url', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet iterates over the specified columns ('headlines', 'description', 'content', 'url', and 'category') in the DataFrame `df`. It applies the `word_tokenize` function from NLTK to each column, effectively splitting the text into individual words or tokens. This process prepares the text data for further NLP tasks such as filtering, stemming, or building frequency distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming Text Columns in DataFrame Using NLTK\n",
    "\n",
    "Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form. This technique is useful in natural language processing (NLP) for simplifying words and reducing the complexity of text data. Below is the code to apply stemming to the text in specific columns of a DataFrame using NLTK's `PorterStemmer`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.stem_columns(['headlines', 'description', 'content', 'url', 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet iterates over the specified columns ('headlines', 'description', 'content', 'url', and 'category') in the DataFrame `df`. For each column, it applies a lambda function that stems each word in the list of tokens using the `PorterStemmer` instance. This process reduces words to their root forms, which can help in simplifying text data and potentially improving the performance of NLP tasks such as text classification or clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rbi, revis, definit, polit, expos, person, ky...</td>\n",
       "      <td>[central, bank, also, ask, chairperson, chief,...</td>\n",
       "      <td>[reserv, bank, india, rbi, chang, definit, pol...</td>\n",
       "      <td>[http, indianexpress, com, articl, busi, bank,...</td>\n",
       "      <td>[busi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ndtv, q2, net, profit, fall, 57, 4, rs, 5, 55...</td>\n",
       "      <td>[ndtv, consolid, revenu, oper, rs, 95, 55, cro...</td>\n",
       "      <td>[broadcast, new, delhi, televis, ltd, monday, ...</td>\n",
       "      <td>[http, indianexpress, com, articl, busi, compa...</td>\n",
       "      <td>[busi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[akasa, air, ‘, well, capitalis, ’, grow, much...</td>\n",
       "      <td>[initi, share, sale, open, public, subscript, ...</td>\n",
       "      <td>[homegrown, server, maker, netweb, technolog, ...</td>\n",
       "      <td>[http, indianexpress, com, articl, busi, marke...</td>\n",
       "      <td>[busi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[india, ’, s, current, account, deficit, decli...</td>\n",
       "      <td>[current, account, deficit, cad, 3, 8, per, ce...</td>\n",
       "      <td>[india, ’, s, current, account, deficit, decli...</td>\n",
       "      <td>[http, indianexpress, com, articl, busi, econo...</td>\n",
       "      <td>[busi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[state, borrow, cost, soar, 7, 68, highest, fa...</td>\n",
       "      <td>[price, shot, reflect, overal, higher, risk, a...</td>\n",
       "      <td>[state, forc, pay, nose, weekli, auction, debt...</td>\n",
       "      <td>[http, indianexpress, com, articl, busi, econo...</td>\n",
       "      <td>[busi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>[samsung, send, invit, ‘, unpack, 2024, ’, new...</td>\n",
       "      <td>[samsung, like, announc, next, gener, galaxi, ...</td>\n",
       "      <td>[samsung, plan, reveal, next, gener, flagship,...</td>\n",
       "      <td>[http, indianexpress, com, articl, technolog, ...</td>\n",
       "      <td>[technolog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>[googl, pixel, 8, pro, accident, appear, offic...</td>\n",
       "      <td>[pixel, 8, pro, like, carri, predecessor, desi...</td>\n",
       "      <td>[googl, accident, gave, us, glimps, upcom, fla...</td>\n",
       "      <td>[http, indianexpress, com, articl, technolog, ...</td>\n",
       "      <td>[technolog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>[amazon, ad, googl, search, redirect, user, mi...</td>\n",
       "      <td>[click, real, look, amazon, ad, open, page, su...</td>\n",
       "      <td>[new, scam, seem, make, round, internet, legit...</td>\n",
       "      <td>[http, indianexpress, com, articl, technolog, ...</td>\n",
       "      <td>[technolog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>[elon, musk, ’, s, x, previous, twitter, worth...</td>\n",
       "      <td>[elon, musk, x, formerli, twitter, lost, half,...</td>\n",
       "      <td>[year, elon, musk, acquir, twitter, 44, billio...</td>\n",
       "      <td>[http, indianexpress, com, articl, technolog, ...</td>\n",
       "      <td>[technolog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>[appl, ’, s, io, 17, 2, updat, releas, here, ’...</td>\n",
       "      <td>[everyth, need, know, major, new, iphon, softw...</td>\n",
       "      <td>[appl, begun, roll, io, 17, 2, updat, elig, ip...</td>\n",
       "      <td>[http, indianexpress, com, articl, technolog, ...</td>\n",
       "      <td>[technolog]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5520 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              headlines  \\\n",
       "0     [rbi, revis, definit, polit, expos, person, ky...   \n",
       "1     [ndtv, q2, net, profit, fall, 57, 4, rs, 5, 55...   \n",
       "2     [akasa, air, ‘, well, capitalis, ’, grow, much...   \n",
       "3     [india, ’, s, current, account, deficit, decli...   \n",
       "4     [state, borrow, cost, soar, 7, 68, highest, fa...   \n",
       "...                                                 ...   \n",
       "5515  [samsung, send, invit, ‘, unpack, 2024, ’, new...   \n",
       "5516  [googl, pixel, 8, pro, accident, appear, offic...   \n",
       "5517  [amazon, ad, googl, search, redirect, user, mi...   \n",
       "5518  [elon, musk, ’, s, x, previous, twitter, worth...   \n",
       "5519  [appl, ’, s, io, 17, 2, updat, releas, here, ’...   \n",
       "\n",
       "                                            description  \\\n",
       "0     [central, bank, also, ask, chairperson, chief,...   \n",
       "1     [ndtv, consolid, revenu, oper, rs, 95, 55, cro...   \n",
       "2     [initi, share, sale, open, public, subscript, ...   \n",
       "3     [current, account, deficit, cad, 3, 8, per, ce...   \n",
       "4     [price, shot, reflect, overal, higher, risk, a...   \n",
       "...                                                 ...   \n",
       "5515  [samsung, like, announc, next, gener, galaxi, ...   \n",
       "5516  [pixel, 8, pro, like, carri, predecessor, desi...   \n",
       "5517  [click, real, look, amazon, ad, open, page, su...   \n",
       "5518  [elon, musk, x, formerli, twitter, lost, half,...   \n",
       "5519  [everyth, need, know, major, new, iphon, softw...   \n",
       "\n",
       "                                                content  \\\n",
       "0     [reserv, bank, india, rbi, chang, definit, pol...   \n",
       "1     [broadcast, new, delhi, televis, ltd, monday, ...   \n",
       "2     [homegrown, server, maker, netweb, technolog, ...   \n",
       "3     [india, ’, s, current, account, deficit, decli...   \n",
       "4     [state, forc, pay, nose, weekli, auction, debt...   \n",
       "...                                                 ...   \n",
       "5515  [samsung, plan, reveal, next, gener, flagship,...   \n",
       "5516  [googl, accident, gave, us, glimps, upcom, fla...   \n",
       "5517  [new, scam, seem, make, round, internet, legit...   \n",
       "5518  [year, elon, musk, acquir, twitter, 44, billio...   \n",
       "5519  [appl, begun, roll, io, 17, 2, updat, elig, ip...   \n",
       "\n",
       "                                                    url     category  \n",
       "0     [http, indianexpress, com, articl, busi, bank,...       [busi]  \n",
       "1     [http, indianexpress, com, articl, busi, compa...       [busi]  \n",
       "2     [http, indianexpress, com, articl, busi, marke...       [busi]  \n",
       "3     [http, indianexpress, com, articl, busi, econo...       [busi]  \n",
       "4     [http, indianexpress, com, articl, busi, econo...       [busi]  \n",
       "...                                                 ...          ...  \n",
       "5515  [http, indianexpress, com, articl, technolog, ...  [technolog]  \n",
       "5516  [http, indianexpress, com, articl, technolog, ...  [technolog]  \n",
       "5517  [http, indianexpress, com, articl, technolog, ...  [technolog]  \n",
       "5518  [http, indianexpress, com, articl, technolog, ...  [technolog]  \n",
       "5519  [http, indianexpress, com, articl, technolog, ...  [technolog]  \n",
       "\n",
       "[5520 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(processor.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
